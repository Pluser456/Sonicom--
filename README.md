# 代码功能

使用 Sonicom 人耳数据集作为神经网络输入，预测个性化HRTF。存储库中的代码仅包含神经网络部分，不包含数据文件。

# 日程更新

## 2025/4/24

### 目前结果（单位 dB）

学姐复现代码：5.7

Resnet（Hutubs）：4.9

Resnet（Sonicom）：5.2

Resnet（Hutubs）Single Frequency：4.2

Average：5.5

Vit（Sonicom）：5.2

### 现在的任务：奚顺加，欧阳洋

1. 修改模型为单个方向看看效果如何，来确定是否是方位角无法识别到导致的欠拟合
结果为5.24dB，证明不是方位角的问题，是神经网络本身无法提取特征。

2. 修改模型为单个频率点看看效果如何，看看能不能识别出来方位角

### 后续的任务：王润邦

1. 把pos_embedding放到transfromer较前面的层中，或者是参考多模态transformer（文本和图像）的输入来修改模型

2. 复现vae的论文代码

### 其他的数据集：

1. 数据集可以考虑widespread，1000个数据集，单纯耳朵的模型，没有人头模型

2. 体素化数据张量，比如说3维位置取128x128点，需要关注模型的尺度是否不变

### 更远的任务：

1. 基于transformer的neural processes

### 2025.4.25

在分支`单位置网络`中，更改了`NewCode`文件夹中之前的 ViT 网络的数据集定义，实现了单空间点的HRTF预测，并修改了对应的计算LSD的代码，在第一个空间点上，LSD结果为5.24dB，相比平均得到的HRTF（LSD为5.35dB）提升不大。并且修复了之前评估LSD的代码的一处错误。在主分支中应该进行相应的修改。

同时，新建了文件夹`NewCNNCode`，利用之前定义在`Code`文件夹中的CNN网络，使用单个空间点的HRTF进行训练，LSD结果为5.26dB，和ViT网络的结果相当。在训练过程中，发现原有的模型的batchnorm层的使用不当，导致模型在测试集上误差极大，去掉该层后模型训练表现回归正常。

### 2025.4.26 wrb
读CVAE1论文：

这篇论文的输入为：三维pos向量 + 12维的人体特征向量（HUTUBS数据）

输入先经过一个AE（作为特征提取）,再经过一个DNN全连接到VAE的Decoder（HRTF的生成模型）上，生成这个方向上的HRTF

各层的大小：

AE：输入层15（3+12） -> 32 ->64 ->128 （在此截断连接至DNN）   ->64 ->32

DNN:输入层128 ->128 ->128->128 ->128->128->输出层16（对应16个采样点）

VAE：输入层103（HRTF点数）->128 ->128->64 ->64->32-> 16个均值 + 16个方差 ->16个采样点（DNN的输出）->32->64->64->128 ->128-> 输出层103（HRTF点数）

总结：15->AE->128 ->DNN->16 ->VAE->103

由于这篇论文使用的是人体参数，所以不适合复现,但是可参考一点如下

主要重点：我们可以考虑将二维的`pos`位置向量改为三维的`pos`坐标向量。

论文原话为：因为一些空间上接近的 HRTFs 在坐标表示上可能略有差异，但在角度表示上可能存在很大差异[例如，(0, 0)和(359, 0)处的 HRTFs]。这种转换已在初步实验中得到证实是有效的。

另外，这篇文章提到在重建HRIR的时候，先使用最小相位重建方法应用于 HRTF 幅度以生成单声道 HRIR；然后，添加 ITD 以合成双耳 HRIR(Zhang et al., 2020)。
相关的论文我们还需要看。重建的论文如下：https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8962233

文章提到的卷积VAE提取耳朵特征论文如下：https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9090538