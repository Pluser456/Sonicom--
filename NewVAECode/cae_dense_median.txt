dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'callbacks', 'optimizer_states', 'lr_schedulers', 'state_dict', 'hparams_name', 'hyper_parameters'])
Layer: cvae.enc.MLP.L0.weight, Size: torch.Size([256, 259])
Layer: cvae.enc.MLP.L0.bias, Size: torch.Size([256])
Layer: cvae.enc.MLP.L1.weight, Size: torch.Size([128, 256])
Layer: cvae.enc.MLP.L1.bias, Size: torch.Size([128])
Layer: cvae.enc.MLP.L2.weight, Size: torch.Size([64, 128])
Layer: cvae.enc.MLP.L2.bias, Size: torch.Size([64])
Layer: cvae.enc.MLP.L3.weight, Size: torch.Size([32, 64])
Layer: cvae.enc.MLP.L3.bias, Size: torch.Size([32])
Layer: cvae.enc.linear_means.weight, Size: torch.Size([32, 32])
Layer: cvae.enc.linear_means.bias, Size: torch.Size([32])
Layer: cvae.enc.linear_log_var.weight, Size: torch.Size([32, 32])
Layer: cvae.enc.linear_log_var.bias, Size: torch.Size([32])
Layer: cvae.dec.MLP.L0.weight, Size: torch.Size([32, 34])
Layer: cvae.dec.MLP.L0.bias, Size: torch.Size([32])
Layer: cvae.dec.MLP.L1.weight, Size: torch.Size([64, 32])
Layer: cvae.dec.MLP.L1.bias, Size: torch.Size([64])
Layer: cvae.dec.MLP.L2.weight, Size: torch.Size([128, 64])
Layer: cvae.dec.MLP.L2.bias, Size: torch.Size([128])
Layer: cvae.dec.MLP.L3.weight, Size: torch.Size([256, 128])
Layer: cvae.dec.MLP.L3.bias, Size: torch.Size([256])
Layer: cvae.dec.MLP.L4.weight, Size: torch.Size([257, 256])
Layer: cvae.dec.MLP.L4.bias, Size: torch.Size([257])